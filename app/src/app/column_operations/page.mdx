export const metadata = {
  title: 'Column Selection',
  description:
    // a description about this Spark chapter that is very SEO friendly
    'Common column operations.',
}

# Column Selection

There are a few different ways to select columns from a dataframe. In this chapter, we'll go over the `select()` and `selectExpr()` functions.

## Build a dummy dataframe

Let's create a simple row of data to work with using the spark.sql() function.

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.getOrCreate()

df = spark.sql("select 'John' as name, 23 as age, 2000 as birth_year")
df.show()
```

```python {{title: "Output"}}
+----+---+----------+
|name|age|birth_year|
+----+---+----------+
|John| 23|      2000|
+----+---+----------+
```

## Using `select()`

The `select()` function allows you to select columns from a dataframe.

```python
# Method 1) Bracket notation
df = df.select(df["name"])

# Method 2) Using column function
from python.sql import functions as F
df = df.select(F.col("name"))

# Method 3) Using a string of the column name
df = df.select("name")
df.show()
```

```python {{title: "Output"}}
+----+
|name|
+----+
|John|
+----+
```

## Using `select()` with literals and expressions

You can also use the `select()` function to create new columns using literals and expressions.

`F.lit` is used to create a column of literal values.

`F.expr` is used to create a column of expressions. For example, using a case statement to create a new column based on the values of other columns.

```python
from pyspark.sql import functions as F

# recreate our dataframe
df = spark.sql("select 'John' as name, 23 as age, 2000 as birth_year")

df = df.select(
    "name",
    "age",
    F.lit("USA").alias("country"),
    F.expr("case when age > 21 then 'adult' else 'minor' end").alias("age_group")
)
df.show()
```

```python {{title: "Output"}}
+----+---+-------+---------+
|name|age|country|age_group|
+----+---+-------+---------+
|John| 23|    USA|    adult|
+----+---+-------+---------+
```


## Using `selectExpr()`

The `selectExpr()` function allows you to pass in SQL expressions as strings. This is useful for performing operations on columns at the same time as you are selecting them.

```python
# recreate our dataframe
df = spark.sql("select 'Kevin' as name, 34 as age, 1990 as birth_year")

df = df.selectExpr("name as first_name", "age + 1 as age_next_year")
df.show()
```

```python {{title: "Output"}}
+----------+-------------+
|first_name|age_next_year|
+----------+-------------+
|     Kevin|           35|
+----------+-------------+
```

<Note>
  **Remember:** `F.col`, `F.lit`, `F.expr` all return a Column object.
</Note>