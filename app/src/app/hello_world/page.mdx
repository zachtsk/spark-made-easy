export const metadata = {
  title: 'Hello World',
  description:
    'Create a spark context and print hello world',
}

# Hello World

One nice thing about Spark is that under the hood, it's basically just a SQL dialect. {{ className: 'lead' }}

(Example notebook can be found [here](https://colab.research.google.com/drive/1IiKGO4POAoKuo7W-ePdEqA9QuGSClFqC?usp=sharing)){{ className: 'lead' }}

<Note>
  The entry point to Spark is the `spark` session object. This is used to tell your Spark cluster what you want to do, whether it's reading data, writing data, or executing a query.
</Note>

```python {{ title: "Python" }}
from pyspark.sql import SparkSession

# 1) Create a spark context
spark = SparkSession.builder.getOrCreate()

# 2) You can use `sql()` to write raw sql queries
df = spark.sql("SELECT 'Hello World' as column_1")

# 3) You can use `show()` to print your dataframe
df.show()

#  +-----------+
#  |   column_1|
#  +-----------+
#  |Hello World|
#  +-----------+
```
